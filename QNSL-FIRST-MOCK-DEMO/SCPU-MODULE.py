import json
import os

# ×¡×™××•×œ×¦×™×™×ª ×–×™×›×¨×•×Ÿ ×œ××™×“×” ××ª××©×›×ª â€“ ×§×•×‘×¥ JSON
MEMORY_FILE = "scpu_memory.json"

def load_memory():
    if os.path.exists(MEMORY_FILE):
        with open(MEMORY_FILE, "r", encoding="utf-8") as f:
            return json.load(f)
    return {
        "requests": [],
        "keywords": [],
        "code_patterns": []
    }

def save_memory(memory_data):
    with open(MEMORY_FILE, "w", encoding="utf-8") as f:
        json.dump(memory_data, f, ensure_ascii=False, indent=2)

def process_data(nlp_data):
    print(f"âŸ¶ [SCPU] ×¢×™×‘×•×“ ×¨×’×©×™Ö¾×©×¤×ª×™ ×•×œ××™×“×” ××ª××©×›×ª...")

    # ×˜×¢×Ÿ ×–×™×›×¨×•×Ÿ ×§×•×“×
    memory = load_memory()

    # ×¢×“×›×•×Ÿ ××™×“×¢ ××”×§×œ×˜ ×”× ×•×›×—×™
    new_keywords = extract_keywords(nlp_data["text"])
    memory["requests"].append(nlp_data["text"])
    memory["keywords"].extend(new_keywords)
    memory["keywords"] = list(set(memory["keywords"]))  # ×”×¡×¨×” ×›×¤×™×œ×•×™×•×ª

    # ×©××•×¨ ×–×™×›×¨×•×Ÿ
    save_memory(memory)

    print(f"  ğŸ§  ××™×œ×™× ×—×“×©×•×ª ×©× ×œ××“×•: {new_keywords}")
    print(f"  ğŸ“ ×–×™×›×¨×•×Ÿ ×›×•×œ×œ: {len(memory['requests'])} ×‘×§×©×•×ª")

    return {
        "nlp": nlp_data,
        "memory": memory
    }

def extract_keywords(text):
    # ×“××• ×©×œ ×—×™×œ×•×¥ ××™×œ×•×ª ××¤×ª×— ××”××©×¤×˜
    common_terms = ["ai", "quantum", "language", "code", "data", "model"]
    return [term for term in common_terms if term in text.lower()]
